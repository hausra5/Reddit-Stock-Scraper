{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit's Most Discussed Stocks\n",
    "In late January of 2021, Reddit, specifically the subreddit Wallstreetbets, made national headlines with the now famous 'meme' stock of Gamestop.  On Wallstreetbets, it was noticed that the short interest float in Gamestop was over 100% which led to a short squeeze that sent the price of Gamestop from around 4 USD all the way to almost 500 USD.  Given this incredible gain, retail investors flooded the market and the userbase of Wallstreetbets grew by millions.\n",
    "\n",
    "Given the success of Gamestop, there have been many stocks that have followed in similar patterns.  As an investor, one would like to stay ahead of the masses and try to pick stocks that may be just gaining interest.  It's very hard to constantly be on these subreddits trying to pick the right stocks.\n",
    "\n",
    "In this project, we utilize Reddit's API to extract what stocks are being discussed most frequently in different subreddits or in actual threads.  In the program we offer the user many different options on where to look, when, to include penny stocks or not, and then we save a dataframe with more information and then a stock ticker count.  The program I wrote is proprietary, so I will only be running and discussing the program for illustrative purposes.\n",
    "\n",
    "Hopefully, by automating the stock ticker counts, we can then research the stocks and make educated decisions on what could possibly be a lucrative stock to invest in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Program\n",
    "The program begins by offering the user a few different options.  We ask if they want to scrape a Thread or Subreddit.  When browsing Reddit, a Subreddit is a section of Reddit dedicated to a topic.  For example, Wallstreetbets is a Subreddit.  Within this Subreddit, there are many different Threads.  Wallstreetbets has daily discussions that are very popular.  A couple of extremely popular Threads are the \"Daily Discussion Thread For (specific date)\" and \"What Are Your Moves For Tomorrow, (specific date)\".  Both of those typically get around 20,000 comments in a day.  \n",
    "\n",
    "When the user chooses Thread, they need to input the exact Thread link.  If they choose Subreddit, they need to specify which one, ie Wallstreetbets, Stocks, Investing, etc.  Continuing with a Subreddit, the user needs to specify what day they are interested in to scrape all the Thread titles for that day.  Then they'll be asked if they want to include the main post for each Thread.  The main post is the section of the Thread where the creator of the Thread includes their post.\n",
    "\n",
    "Regardless of whether the user chooses Thread or Subreddit, the next question will be if they want to include Penny Stocks.  Penny Stocks are very risky and volatile.  They also aren't listed on the main Stock Exchanges and some platforms don't even let you trade them.  Due to this, Subreddits like Wallstreetbets and Stocks ban those tickers from being discussed.  So the user may not want to include these since they're not supposed to be discussed in these Subreddits.  However, if the user is interested in Subreddits such as Pennystocks, they'll want to include these.\n",
    "\n",
    "Lastly, the user is asked what name they want to save the Dataframe as.  Once the program has scraped and counted all tickers, the user can have access to the stock ticker counts and the full dataframe containing all the comments to explore further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How the Program Works\n",
    "The program utilizes the PRAW library to converse with Reddit's API to scrape the data.  On the backend of PRAW, when scraping the data, PRAW helps by automatically parsing the JSON and extracting out what the user is requesting.  This can be anything like comments, titles, dates, etc.\n",
    "\n",
    "Based on what the user asked to scrape for, the program will then compile a Dataframe and print out the Titles, Comments, etc.  For display purposes in Jupyter, we limited this to the first 10 posts.  Once the Dataframe is compiled, we save it as a CSV file.\n",
    "\n",
    "Next, we import all of the Stock Exchanges Tickers and Security Names.  If the user requested to include Penny Stocks, we then import those as well.  We do some data cleaning to extract out just the Ticker and Security Name in the format that will help with the counting.  We have a list of frequently misclassfied Tickers that we then drop from the Dataframe to help keep the counts accurate at the end of the program.  Once clean, we create a dictionary with all the Ticker's and Security name's with a 0 count.  Using regular expressions, we then loop through the Dataframe and anytime a Ticker or Security Name is mentioned, we increase the count.  \n",
    "\n",
    "Once the loop is complete, we sort the values and print out the top 20 tickers discussed.  For fun, we display how long the program took to run and then exit.  The user now as access to the Ticker Count and Master DataFrame CSV files to explore further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Program on a Subreddit\n",
    "We will now run the program for a Subreddit's Titles and Main Posts.  Again for illustration purposes, we limited the print out of Post Titles to the first 10 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread or Subreddit?: subreddit\n",
      "Which subreddit? ie. wallstreetbets: wallstreetbets\n",
      "What day? Must be in the last few days (9,10,11,etc.): 18\n",
      "Include main post?: yes\n",
      "Include Penny Stocks?: no\n",
      "Save DataFrame under what filename?: wsb_titles+MP_June_18_2021\n",
      "Extracting comments...\n",
      "------------------------------------------------------------\n",
      "POST TITLE#  1 :  Guys SPY usually recovers within a month right?\n",
      "POST TITLE#  2 :  AMZN PrimeDay Calls. Moonday Tuesday Print?\n",
      "POST TITLE#  3 :  $WISH 🚀 ALL IN with my father’s inheritance! IMMA MAKE YOU PROUD POPS rip 🥲\n",
      "POST TITLE#  4 :  I just bet against SPY and the DOW based on some DD. Am I stupid?\n",
      "POST TITLE#  5 :  Wall Street Week Ahead for the trading week beginning June 21st, 2021\n",
      "POST TITLE#  6 :  It ain’t much but YOLO quad witching w/ NVDA\n",
      "POST TITLE#  7 :  Life Savings $WISH Yolo\n",
      "POST TITLE#  8 :  SP500 Winners and Losers | 6/18/2021\n",
      "POST TITLE#  9 :  WISH 45 C 7/16\n",
      "POST TITLE#  10 :  I started monday with 5 contracts, kept doubling down as the price dropped\n",
      "------------------------------------------------------------\n",
      "Done!\n",
      "Saving DF...\n",
      "Saved!\n",
      "------------------------------------------------------------\n",
      "Counting Tickers...\n",
      "------------------------------------------------------------\n",
      "TOP 20 TICKERS:\n",
      "           Ticker  Count\n",
      "0             AMC     27\n",
      "1            UWMC     21\n",
      "2             HSY     19\n",
      "3        PALANTIR     15\n",
      "4            DKNG     15\n",
      "5            CLNE     14\n",
      "6             GME     14\n",
      "7            PLTR     13\n",
      "8         MYOVANT     12\n",
      "9      BLACKBERRY     12\n",
      "10        CUREVAC     10\n",
      "11          CANOO     10\n",
      "12          TESLA     10\n",
      "13           SHIP     10\n",
      "14        TWITTER     10\n",
      "15         PFIZER      9\n",
      "16      LORDSTOWN      9\n",
      "17  ARCELORMITTAL      8\n",
      "18           WKHS      7\n",
      "19            SPY      7\n",
      "------------------------------------------------------------\n",
      "Saving full list of used tickers...\n",
      "SUCCESS!\n",
      "------------------------------------------------------------\n",
      "The program took 1 minutes and 37 seconds to finish.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run reddit_j.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the program was a success!  It only took 1 minute and 37 seconds and it extracted out the most discussed Tickers.  We can see that within the Title + Main Post's for June 18th on Wallstreetbets, AMC, UWMC, HSY, PALANTIR, and DKGN were the top 5.  We can see that PLTR (the actual Ticker for Palantir) was also in the top 10. Combining those two together acutally puts PLTR as the most talked about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Program on a Thread\n",
    "We will now run the program on a Thread.  With threads typically having thousands of posts, the more data we get, the more accurate our program will become.  Since Wallstreetbets really started this movement and the Daily Discussion Threads offer the most comments, this will give us a better picture on what's being discussed the most. \n",
    "\n",
    "Let's run the program on the \"What are your Moves Tomorrow, June 21, 2021\".  Again for illustration purposes, we limited the print out of comments to the first 10 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread or Subreddit?: thread\n",
      "What is the full Reddit Thread Link?: https://www.reddit.com/r/wallstreetbets/comments/o4dpla/what_are_your_moves_tomorrow_june_21_2021/\n",
      "Include Penny Stocks?: no\n",
      "Save DataFrame under what filename?: wsb_moves_tom_June_21_2021\n",
      "Extracting comments...\n",
      "------------------------------------------------------------\n",
      "TITLE:  What Are Your Moves Tomorrow, June 21, 2021\n",
      "------------------------------------------------------------\n",
      "MAIN POST:  Your daily trading discussion thread. Please keep the shitposting to a minimum.  .......\n",
      "------------------------------------------------------------\n",
      "Extracting comments...\n",
      "POST#  1 :  Seeing doom and gloom about futures and the market here in wsb Sunday night.\n",
      "\n",
      "Wake up Monday to green everywhere. \n",
      "\n",
      "This is the way.\n",
      "POST#  2 :  Lehman Brothers and Bear Stearns seem like obvious buys.\n",
      "POST#  3 :  GUH \n",
      "\n",
      "Sorry guys I’m practicing for tomorrow\n",
      "POST#  4 :  It’s only when a mosquito lands on your balls that you realize there is always a way to solve a problem without violence\n",
      "POST#  5 :  You guys ever feel like your body is just slowly falling apart and failing, but your doctor says you’re only 35 and these things shouldn’t be happening to someone under 75\n",
      "POST#  6 :  US businesses are pushing for another bailout…how could you be a bear right now when the money printer is about to go into overdrive ?\n",
      "\n",
      "We will literally print money right until we go flying off the cliff.\n",
      "\n",
      "Those of you that aren’t American don’t understand, it has become political to not raise rates because it’s like hot potatoe; whoever raises rates will anihilate the economy and get blamed for probably decades.\n",
      "\n",
      "So they keep kicking the can.  And America can kick the can for sure for a few more years.  Shit maybe even longer.\n",
      "POST#  7 :  Market goes down on me more than my ex ever did\n",
      "POST#  8 :  A Haiku:\n",
      "\n",
      "market is open\n",
      "\n",
      "all my money is gone now\n",
      "\n",
      "market is closed now\n",
      "POST#  9 :  My first son is being born today. Wish me luck\n",
      "POST#  10 :  DOW is for boomers. I only care about that sweet sweet NASDAQ\n",
      "------------------------------------------------------------\n",
      "Done!\n",
      "Saving DF...\n",
      "Saved!\n",
      "------------------------------------------------------------\n",
      "Counting Tickers...\n",
      "------------------------------------------------------------\n",
      "TOP 20 TICKERS:\n",
      "   Ticker  Count\n",
      "0     SPY    346\n",
      "1     GME    127\n",
      "2    WKHS    109\n",
      "3    CLOV     98\n",
      "4     CLF     90\n",
      "5    UWMC     69\n",
      "6    PLTR     68\n",
      "7    TSLA     66\n",
      "8    NVDA     64\n",
      "9    TLRY     50\n",
      "10    AMC     44\n",
      "11    AMD     42\n",
      "12   CLNE     37\n",
      "13      F     34\n",
      "14    TLT     33\n",
      "15  TESLA     33\n",
      "16    AIN     29\n",
      "17   CRSR     28\n",
      "18    NIO     27\n",
      "19  DELTA     27\n",
      "------------------------------------------------------------\n",
      "Saving full list of used tickers...\n",
      "SUCCESS!\n",
      "------------------------------------------------------------\n",
      "The program took 34 minutes and 27 seconds to finish.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run reddit_j.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!  The program took 34 minutes and 27 seconds to finish and our top 5 Stock Tickers are Spy, GME, WKHS, CLOV, and CLF.  Now that we ran this, let's read in the master dataframe to take a look at the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None, 'display.max_columns', None)\n",
    "wsb_moves = pd.read_csv('wsb_moves_tom_June_21_2021/wsb_moves_tom_June_21_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What Are Your Moves Tomorrow, June 21, 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Your daily trading discussion thread. Please k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Seeing doom and gloom about futures and the ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Lehman Brothers and Bear Stearns seem like obv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GUH \\n\\nSorry guys I’m practicing for tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               body\n",
       "0           0        What Are Your Moves Tomorrow, June 21, 2021\n",
       "1           1  Your daily trading discussion thread. Please k...\n",
       "2           2  Seeing doom and gloom about futures and the ma...\n",
       "3           3  Lehman Brothers and Bear Stearns seem like obv...\n",
       "4           4     GUH \\n\\nSorry guys I’m practicing for tomorrow"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsb_moves.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that above we saw that SPY was the number one most discussed stock, it may be helpful to filter the dataframe on SPY and see what the comments look like for that ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>I don't understand why 10Y is dropping so hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>The rate hike is already socialized, SPY 422 eow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>SPY collapse tomorrow.  I’m selling everything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>139</td>\n",
       "      <td>You ever made 10x on SPY calls? Well this is y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>No end in sight to the selloff. No apparent sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>SPY is barely even down. Why are people so sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>201</td>\n",
       "      <td>Guys, historically SPY always bounces off the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>251</td>\n",
       "      <td>Guh, futures are bright red…Guess I better sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>i’m down to my last $500 — started with $2k, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>Fuck SPY it is QQQ summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>Calls on SPY right at open?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>SPY +1% today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>It's so cool that we are back to talking about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>314</td>\n",
       "      <td>I swear to god, Futures go -.5% and suddenly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>325</td>\n",
       "      <td>SPY 06/23 415C Double or Nothing Fuck It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>341</td>\n",
       "      <td>SPY puts this week like “it’s Britney bitch”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>348</td>\n",
       "      <td>Awful lot of volume on SPY Friday.  Feel like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>435</td>\n",
       "      <td>I listen to dramatic operatic/classical music ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>466</td>\n",
       "      <td>That weekly candle with the gap looks reeeeeea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>469</td>\n",
       "      <td>I bought SPY calls this past Friday. Am I fuck...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               body\n",
       "76           76  I don't understand why 10Y is dropping so hard...\n",
       "90           90   The rate hike is already socialized, SPY 422 eow\n",
       "128         128  SPY collapse tomorrow.  I’m selling everything...\n",
       "139         139  You ever made 10x on SPY calls? Well this is y...\n",
       "158         158  No end in sight to the selloff. No apparent sh...\n",
       "195         195  SPY is barely even down. Why are people so sca...\n",
       "201         201  Guys, historically SPY always bounces off the ...\n",
       "251         251  Guh, futures are bright red…Guess I better sta...\n",
       "271         271  i’m down to my last $500 — started with $2k, w...\n",
       "277         277                          Fuck SPY it is QQQ summer\n",
       "278         278                        Calls on SPY right at open?\n",
       "295         295                                      SPY +1% today\n",
       "301         301  It's so cool that we are back to talking about...\n",
       "314         314  I swear to god, Futures go -.5% and suddenly p...\n",
       "325         325           SPY 06/23 415C Double or Nothing Fuck It\n",
       "341         341       SPY puts this week like “it’s Britney bitch”\n",
       "348         348  Awful lot of volume on SPY Friday.  Feel like ...\n",
       "435         435  I listen to dramatic operatic/classical music ...\n",
       "466         466  That weekly candle with the gap looks reeeeeea...\n",
       "469         469  I bought SPY calls this past Friday. Am I fuck..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPY = wsb_moves[wsb_moves['body'].str.contains('SPY')]\n",
    "SPY.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first 20 comments about SPY, the overall sentiment seems to be negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "I am constantly updating this program and it needs to evolve to become better and more useful.  One next step that I am currently working on is to have the count combine the Ticker and Security Name to fix the above issue in the Subreddit Ticker Count (ie. PALANTIR AND PLTR).  \n",
    "\n",
    "The most important next step I'm working on is adding a Machine Learning algorithm to analyze the overall sentiment for each Ticker discussed.  For example, above, looking at the first 20 comments on SPY, the sentiment seemed negative.  The goal of the algorithm would be to go through all of the comments for each ticker and conclude as to whether the sentiment is negative or positive.  \n",
    "\n",
    "Knowing how many times a Stock is mentioned is helpful to pick up on trends.  However, to make the program more useful, knowing the overall sentiment of the stock can help the investor make a smarter purchase.  Knowing the sentiment and can help lead the investor to know whether to buy or sell, or when to utilize options such as Puts and Calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
